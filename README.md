# Case_Breweries_Abinbev

O desafio deste case foi desenvolver um pipeline de dados para buscar, processar e armazenar informaÃ§Ãµes de cervejarias a partir da API Open Brewery DB. O pipeline segue uma arquitetura em camadas (bronze, prata e ouro) para estruturar e transformar os dados ao longo do processo.

<img src="/imgs/arquiteture_draw.png" />

> ðŸ’¾ esboÃ§o da arquitetura


## Resumo dos principais conceitos e technologias utilizadas.
* Pipeline criada na DAG do Airflow
* Airflow rodando localmente dentro de um container (docker)
* Processamento realizado via Spark tambÃ©m dentro do container (docker)
* Armazenamento respeitando a arquitetura medalion (dados raw json, silver & gold delta  [lakehouse])
* Boas prÃ¡ticas em desenvolvimento de soluÃ§Ãµes, o cÃ³digo Ã© mantido em mÃ³dulos separados e bem documentados para facilitar a leitura e o debug.
* Brinquei um pouco com o conceito de dataquality na dag.
* Brinquei um pouco com o conceito de monitoramento.


Segue abaixo uma imagem do painel de controle das runs de nossa dag.

<img src="/imgs/dag_sample.png" />


#### Estrutura de diretÃ³rios e arquivos:
```
zcase_ambev/
â”œâ”€â”€ config/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ brew_dag.py
â”œâ”€â”€ lakehouse/
â”‚   â”œâ”€â”€ bronze_layer/
â”‚   â”œâ”€â”€ silver_layer/
â”‚   â”œâ”€â”€ golden_layer/
â”‚   â”œâ”€â”€ logs/
â”œâ”€â”€ monitoring/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ brew_api/
â”‚   â”‚   â”‚   â”œâ”€â”€ brewapi_bronze.py
â”‚   â”‚   â”œâ”€â”€ spark_utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ delta_spark.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ configs.json
â”‚   â”‚   â”‚   â”œâ”€â”€ monitor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”‚   â”œâ”€â”€ sample_validation.py
â”‚   â”œâ”€â”€ api_to_bronze.py
â”‚   â”œâ”€â”€ bronze_to_silver.py
â”‚   â”œâ”€â”€ silver_to_gold.py
â”‚   â”œâ”€â”€ validation.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```

## DescriÃ§Ã£o da Dag [brew_dag.py]

<img src="/imgs/dag_brew.png" />

* Primeira task:
    * ResponsÃ¡vel por extrair os dados da API e persistir seus dados na camada bronze.
* Segunda task:
    * ResponsÃ¡vel por validar se os dados persistidos na camada bronze possuem o mesmo valor do endpoint "total" dos metadados da API. Aqui tambÃ©m temos uma validaÃ§Ã£o na estrutura do schema dos dados da camada bronze.
* Terceira task:
    * Essa task Ã© uma funcionalidade que confere se a validaÃ§Ã£o da "Segunda task" deu certo, abrindo a opÃ§Ã£o de um caminho de dag secundÃ¡rio em caso de erro.
* Quarta task:
    * ResponsÃ¡vel, em caso de erro (aqui estamos falando de um caso hipotÃ©tico), por realizar alguma aÃ§Ã£o preventiva ou paliativa, exemplo: Enviar uma mensagem para o time de ingestÃ£o avisando sobre o erro da validaÃ§Ã£o, ou realizar mais algumas tasks que buscam mitigar ou atÃ© voltar para a primeira task.
* Quinta task:
    * ResponsÃ¡vel por consumir os dados da camada bronze, realizar transformaÃ§Ãµes como remoÃ§Ã£o de caracteres especiais das colunas, garantir a transformaÃ§Ã£o das colunas de latitude e longitude no formato float (dentro dos padrÃµes corretos). A persistÃªncia de dados na camada silver Ã© feita por arquivos do tipo delta, que possuem N vantagens. Aqui, de maneira breve, podemos falar sobre sua Ã³tima performance. Por Ãºltimo, nos requisitos, era pedido para salvar os dados por regiÃ£o. Optamos, por motivos de performance, por escolher o paÃ­s como coluna para partiÃ§Ã£o, pois no nosso universo de dados atual, se a partiÃ§Ã£o fosse feita por menor granularidade, poderÃ­amos lidar com o problema de *small file* (se Ã© que jÃ¡ nÃ£o estamos lidando).
* Sexta task:
    * ResponsÃ¡vel por consumir os dados da silver, realizar agregaÃ§Ãµes pertinentes a regras de negÃ³cio, visando otimizaÃ§Ã£o na hora do consumo dos dados da camada gold (onde Ã© feita a persistÃªncia apÃ³s essas transformaÃ§Ãµes). No caso aqui, Ã© uma simples agregaÃ§Ã£o:
    *groupBy('brewery_type', 'country', 'state', 'city').count()*
    
### Mais alguns detalhes sobre a DAG.

O conceito de validaÃ§Ã£o foi explorado de maneira simples. O objetivo aqui era apenas trazer uma breve ideia sobre o caminho a ser seguido no quesito de qualidade de dados. Diversas implementaÃ§Ãµes poderiam ser feitas, como: Sistema de mensageria (avisar os times), outras tasks adicionais (erros conhecidos e contornados de APIs inconsistentes). Entre as outras tasks, tambÃ©m poderiam ser feitas validaÃ§Ãµes com regras de negÃ³cio (GreatExpectations por exemplo), testes diversos para garantir que os dados que estÃ£o sendo entregues para o DOWNSTREAM sejam de fato coerentes com a necessidade do cliente final.

Nas tasks principais (1, 5, 6), explorei de maneira simples o monitoramento das execuÃ§Ãµes, criando um diretÃ³rio separado que registra o tempo de duraÃ§Ã£o de cada task. Isso permite acompanhar o desempenho e identificar possÃ­veis gargalos ou atrasos. AlÃ©m disso, ferramentas como Prometheus ou Grafana podem ser integradas ao Airflow para fornecer um monitoramento mais detalhado, com dashboards que acompanham mÃ©tricas como a duraÃ§Ã£o das tasks e o nÃºmero de execuÃ§Ãµes, facilitando a visualizaÃ§Ã£o e anÃ¡lise da performance do pipeline.


## Pontos de melhoria

Quando comecei o case, estava mirando em fazer no EKS (via Terraform e Argo), porÃ©m meu PC queimou (Minikube sem condiÃ§Ãµes no PC fraquinho) no meio do processo (alÃ©m da surra que tomei das permissÃµes da AWS), e acabei com essa soluÃ§Ã£o mais simples. Dito isso, vou listar os pontos de melhoria.

* Escalabilidade: Esta soluÃ§Ã£o faz mau uso da computaÃ§Ã£o distribuÃ­da do Spark. Atualmente, temos uma soluÃ§Ã£o que roda o Spark em apenas um worker do Airflow, o que pode facilmente gerar gargalos em cenÃ¡rios produtivos. Portanto, a soluÃ§Ã£o deve migrar para um ambiente onde o Spark possa escalar seus workers e ter alta disponibilidade. De imediato, penso na utilizaÃ§Ã£o do SPOK (Spark Operator for Kubernetes), permitindo uma conexÃ£o eficiente entre Spark, Airflow e Kubernetes, com alto desempenho.

* Esteiras de CI/CD: Aproveitando o gancho do Kubernetes, as esteiras de CI/CD tÃªm um grande potencial para a prÃ³xima etapa da soluÃ§Ã£o, garantindo uma infraestrutura como cÃ³digo (IaC) bem feita junto com o ArgoCD. As esteiras podem criar e destruir o cluster conforme a necessidade de negÃ³cio, proporcionando uma soluÃ§Ã£o altamente elÃ¡stica (FinOps agradece). AlÃ©m disso, as esteiras podem incluir mais etapas de testes e segregaÃ§Ã£o de ambientes, possibilitando mitigar ainda mais as falhas de desenvolvimento.

## Passos para executar o projeto.
### atenÃ§Ã£o projeto desenvolvido em ambiente ubunto
### Requisitos
docker 

* Clonar repo:
```sh
gitclone https://github.com/Gabriel-Philot/Case_Breweries_Abinbev.git
```
>[!Note]
> Deletar diretorios (menos src!!!) para iniciar do zero... (deixam fora do ignore pois estÃ£o dentro do contexto da soluÃ§Ã£o)

* Criar dirs necessarios para a soluÃ§Ã£o:
```sh
mkdir -p ./config ./src ./src/resources ./logs ./lakehouse ./lakehouse/bronze_layer ./lakehouse/silver_layer ./lakehouse/golden_layer ./monitoring
```
* Facilitar permissÃµes do linux...:
```sh
sudo chmod -R 777 ./config ./src ./src/resources ./logs ./lakehouse ./lakehouse/bronze_layer ./lakehouse/silver_layer ./lakehouse/golden_layer ./monitoring
```

* criar sua imagem docker no root:
```sh
docker build -t {nome da sua imagem} .
```

> [!Note]
> AtenÃ§Ã£o para alterar o nome no compose na linha 52

```sh
docker compose up -d
```
apos o airflow subir


* acessar o webserver do airflow:
```sh
http://localhost:8080/
```
acessar a dag e por ela pra rodar.