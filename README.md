# Case_Breweries_Abinbev

O desafio deste case foi desenvolver um pipeline de dados para buscar, processar e armazenar informa√ß√µes de cervejarias a partir da API Open Brewery. O pipeline segue uma arquitetura em camadas (bronze, prata e ouro) para estruturar e transformar os dados ao longo do processo.

<img src="/imgs/arquiteture_draw.png" />

> üíæ esbo√ßo da arquitetura

## Resumo dos principais conceitos e technologias utilizadas.
* Pipeline criada na DAG do Airflow
* Airflow rodando localmente dentro de um container (docker)
* Processamento realizado via Spark tamb√©m dentro do container (docker)
* Armazenamento respeitando a arquitetura medalion (dados raw json, silver & gold delta  [lakehouse])
* Boas pr√°ticas em desenvolvimento de solu√ß√µes, o c√≥digo √© mantido em m√≥dulos separados e bem documentados para facilitar a leitura e o debug.
* Brinquei um pouco com o conceito de dataquality na dag.
* Brinquei um pouco com o conceito de monitoramento.


Segue abaixo uma imagem do painel de controle das runs de nossa dag.

<img src="/imgs/dag_sample.png" />


#### Estrutura de diret√≥rios e arquivos:
```
zcase_ambev/
‚îú‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ brew_dag.py
‚îú‚îÄ‚îÄ lakehouse/
‚îÇ   ‚îú‚îÄ‚îÄ bronze_layer/
‚îÇ   ‚îú‚îÄ‚îÄ silver_layer/
‚îÇ   ‚îú‚îÄ‚îÄ golden_layer/
‚îÇ   ‚îú‚îÄ‚îÄ logs/
‚îú‚îÄ‚îÄ monitoring/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ resources/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brew_api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brewapi_bronze.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spark_utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ delta_spark.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configs.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_validation.py
‚îÇ   ‚îú‚îÄ‚îÄ api_to_bronze.py
‚îÇ   ‚îú‚îÄ‚îÄ bronze_to_silver.py
‚îÇ   ‚îú‚îÄ‚îÄ silver_to_gold.py
‚îÇ   ‚îú‚îÄ‚îÄ validation.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ data_viz_notebook.ipynb
‚îú‚îÄ‚îÄ requirements.txt
```

> üçÄ Visualiza√ß√£o dos dados nas camadas: [data_viz_notebook.ipynb](https://github.com/Gabriel-Philot/Case_Breweries_Abinbev/blob/main/data_viz_notebook.ipynb)


## Descri√ß√£o da Dag [brew_dag.py]

<img src="/imgs/dag_brew.png" />

* Primeira task:
    * Respons√°vel por extrair os dados da API [https://openbrewerydb.org/] (modficiar/paginar o endpoint para extra√ß√£o adequada dos dados) e persistir seus dados na camada bronze.
* Segunda task:
    * Respons√°vel por validar se os dados persistidos na camada bronze possuem o mesmo valor do endpoint "total" dos metadados da API. Aqui tamb√©m temos uma valida√ß√£o na estrutura do schema dos dados da camada bronze.
* Terceira task:
    * Essa task √© uma funcionalidade que confere se a valida√ß√£o da "Segunda task" deu certo, abrindo a op√ß√£o de um caminho de dag secund√°rio em caso de erro.
* Quarta task:
    * Respons√°vel, em caso de erro (aqui estamos falando de um caso hipot√©tico), por realizar alguma a√ß√£o preventiva ou paliativa, exemplo: Enviar uma mensagem para o time de ingest√£o avisando sobre o erro da valida√ß√£o, ou realizar mais algumas tasks que buscam mitigar ou at√© voltar para a primeira task.
* Quinta task:
    * Respons√°vel por consumir os dados da camada bronze, realizar transforma√ß√µes como remo√ß√£o de caracteres especiais das colunas, garantir a transforma√ß√£o das colunas de latitude e longitude no formato float (dentro dos padr√µes corretos). A persist√™ncia de dados na camada silver √© feita por arquivos do tipo delta, que possuem N vantagens. Aqui, de maneira breve, podemos falar sobre sua √≥tima performance. Por √∫ltimo, nos requisitos, era pedido para salvar os dados por regi√£o. Optamos, por motivos de performance, por escolher o pa√≠s como coluna para parti√ß√£o, pois no nosso universo de dados atual, se a parti√ß√£o fosse feita por menor granularidade, poder√≠amos lidar com o problema de *small file* (se √© que j√° n√£o estamos lidando).
* Sexta task:
    * Respons√°vel por consumir os dados da silver, realizar agrega√ß√µes pertinentes a regras de neg√≥cio, visando otimiza√ß√£o na hora do consumo dos dados da camada gold (onde √© feita a persist√™ncia ap√≥s essas transforma√ß√µes). No caso aqui, √© uma simples agrega√ß√£o:
    *groupBy('brewery_type', 'country', 'state', 'city').count()*
    
### Mais alguns detalhes sobre a DAG.

O conceito de valida√ß√£o foi explorado de maneira simples. O objetivo aqui era apenas trazer uma breve ideia sobre o caminho a ser seguido no quesito de qualidade de dados. Diversas implementa√ß√µes poderiam ser feitas, como: Sistema de mensageria (avisar os times), outras tasks adicionais (erros conhecidos e contornados de APIs inconsistentes). Entre as outras tasks, tamb√©m poderiam ser feitas valida√ß√µes com regras de neg√≥cio (GreatExpectations por exemplo), testes diversos para garantir que os dados que est√£o sendo entregues para o DOWNSTREAM sejam de fato coerentes com a necessidade do cliente final.

Nas tasks principais (1, 5, 6), explorei de maneira simples o monitoramento das execu√ß√µes, criando um diret√≥rio separado que registra o tempo de dura√ß√£o de cada task. Isso permite acompanhar o desempenho e identificar poss√≠veis gargalos ou atrasos. Al√©m disso, ferramentas como Prometheus ou Grafana podem ser integradas ao Airflow para fornecer um monitoramento mais detalhado, com dashboards que acompanham m√©tricas como a dura√ß√£o das tasks e o n√∫mero de execu√ß√µes, facilitando a visualiza√ß√£o e an√°lise da performance do pipeline.


## Pontos de melhoria

Quando comecei o case, estava mirando em fazer no EKS (via Terraform e Argo), por√©m meu PC queimou (Minikube sem condi√ß√µes no PC fraquinho) no meio do processo (al√©m da surra que tomei das permiss√µes da AWS), acabei com essa solu√ß√£o mais simples. Dito isso, vou listar os pontos de melhoria.

* Escalabilidade: Esta solu√ß√£o faz mau uso da computa√ß√£o distribu√≠da do Spark. Atualmente, temos uma solu√ß√£o que roda o Spark em apenas um worker do Airflow, o que pode facilmente gerar gargalos em cen√°rios produtivos. Portanto, a solu√ß√£o deve migrar para um ambiente onde o Spark possa escalar seus workers e ter alta disponibilidade. De imediato, penso na utiliza√ß√£o do SPOK (Spark Operator for Kubernetes), permitindo uma conex√£o eficiente entre Spark, Airflow e Kubernetes, com alto desempenho.


* Esteiras de CI/CD: Aproveitando o gancho do Kubernetes, as esteiras de CI/CD t√™m um grande potencial para a pr√≥xima etapa da solu√ß√£o, garantindo uma infraestrutura como c√≥digo (IaC) bem feita junto com o ArgoCD. As esteiras podem criar e destruir o cluster conforme a necessidade de neg√≥cio, proporcionando uma solu√ß√£o altamente el√°stica (FinOps agradece). Al√©m disso, as esteiras podem incluir mais etapas de testes e segrega√ß√£o de ambientes, possibilitando mitigar ainda mais as falhas de desenvolvimento.


## Passos para executar o projeto.
>[!Note]
> Projeto desenvolvido em ambiente ubunto


### Requisitos: docker


* Clonar repo:
```sh
gitclone https://github.com/Gabriel-Philot/Case_Breweries_Abinbev.git
```
>[!Note]
> Deletar diretorios (menos src!!!) para iniciar do zero... (deixam fora do ignore pois est√£o dentro do contexto da solu√ß√£o)

* Criar dirs necessarios para a solu√ß√£o:
```sh
mkdir -p ./config ./src ./src/resources ./logs ./lakehouse ./lakehouse/bronze_layer ./lakehouse/silver_layer ./lakehouse/golden_layer ./monitoring
```
* Facilitar permiss√µes do linux...:
```sh
sudo chmod -R 777 ./config ./src ./src/resources ./logs ./lakehouse ./lakehouse/bronze_layer ./lakehouse/silver_layer ./lakehouse/golden_layer ./monitoring
```

* criar sua imagem docker no root:
```sh
docker build -t {nome da sua imagem} .
```

> [!Note]
> Aten√ß√£o para alterar o nome no compose na linha 52

```sh
docker compose up -d
```
apos o airflow subir


* acessar o webserver do airflow:
```sh
http://localhost:8080/
```
login e senha: airflow

entrar na parte de dags e acionar a brew_dag.py



## Conslus√£o & Agradecimentos
Ao longo deste projeto, foi poss√≠vel implementar um fluxo completo de ETL utilizando v√°rias ferramentas open source amplamente utilizadas no mundo de engenharia de dados.
Concerteza foi um case bem legal de ser feito, bem completo e da para evoluir muito em cima dele.
Agrade√ßo desde j√° pela oportuinidade e sigo aberto para qualquer questionamento.

Att, [Gabriel-Philot](https://www.linkedin.com/in/gabriel-philot/)